{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  XMLToSnowflakeParser\n",
    "    Purpose: Parser XMLToSnowflakeParser\n",
    "    Module Namer: XMLToSnowflakeParser.py\n",
    "    Author: Sophia Yue adapted the code from  Mohit Sachdeva \n",
    "    Date: Dec 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module Namer: XMLToSnowflakeParser.py\n",
    "Author:Mohit Sachdeva \n",
    "Date: Dec 2019\n",
    "\"\"\"\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "def parseXML(root,sm):\n",
    "    sm = sm + \"/\" + root.tag[root.tag.rfind('}')+1:]\n",
    "    for child in root:\n",
    "      parseXML(child,sm)\n",
    "    if len(list(root)) == 0:\n",
    "        my_list.append(sm)\n",
    "def colList():\n",
    "    \"\"\"Prepares the list of columns from the XML tags list. This column list will be used for DataFrame creation.\"\"\"  \n",
    "    len_max = 0\n",
    "    for txt in my_list:\n",
    "        split_tags = txt.split('/')\n",
    "        len_curr = len(split_tags)\n",
    "        if len_curr >= len_max:\n",
    "            len_max = len_curr\n",
    "        #last3.append(split_tags[-8:])\n",
    "    print (\"max length %d\" %len_max)\n",
    "    for i in range(1, len_max+1):\n",
    "        col_nm = \"column\" + str(i)\n",
    "        cols.append(col_nm)\n",
    "    print (cols)\n",
    "    return (len_max)\n",
    "def splitTags(len_max):\n",
    "    \"\"\"Splits the XML path into individual tags and stored in list. This list will be used to populate DataFrame.\"\"\"\n",
    "    for txt in my_list:\n",
    "        split_tags = txt.split('/')\n",
    "        path_list.append(txt.rsplit('/', 1))\n",
    "        all_tags.append(split_tags[-len_max:])\n",
    "        last1.append([split_tags[-1:],len(split_tags)])\n",
    "        i=1\n",
    "        strg = '/'\n",
    "        for s in split_tags[1:len(split_tags)-1]:\n",
    "            strg = strg + str(i) + \"_\" + s + \"/\"\n",
    "            i = i+1\n",
    "        sort_path.append(strg)\n",
    "def renameDupCols(merge_df):\n",
    "    \"\"\"Append the pranet XML tag to the duplicate/repeated elements and overcolumn in dataframe\"\"\"\n",
    "    dup_df = merge_df[merge_df.duplicated(['sel_col'],keep=False)]\n",
    "    i=1\n",
    "    while not dup_df.empty:\n",
    "        merge_df = merge_df.join(dup_df['sel_col'],rsuffix='_right')\n",
    "        for index, row in merge_df.iterrows():\n",
    "            if row.sel_col == row.sel_col_right:\n",
    "                cl = \"column\" + str(row.sel_col_pos - i)\n",
    "                new_col = row[cl] + \"_\" + row.sel_col\n",
    "            else:\n",
    "                new_col = row.sel_col\n",
    "            merge_df['sel_col'][index] = new_col\n",
    "        del merge_df['sel_col_right']\n",
    "        dup_df = merge_df[merge_df.duplicated(['sel_col'],keep=False)]\n",
    "        i=i+1\n",
    "        print(i)\n",
    "    sel_col_lst = merge_df['sel_col'].tolist()\n",
    "    for cls in sel_col_lst:\n",
    "        if cls.count('_') > 1:\n",
    "            split_cols = cls.split('_')\n",
    "            col_str = split_cols[0]+\"_\"+split_cols[-1]\n",
    "            new_col_lst.append(col_str)\n",
    "        else:\n",
    "            new_col_lst.append(cls)\n",
    "    merge_df['new_sel_col'] = new_col_lst\n",
    "    return merge_df\n",
    "def createDDL(merge_df):\n",
    "    \"\"\"Prepares DDL statements and writes into the File\"\"\"\n",
    "    ddl = \"CREATE OR REPLACE TABLE \"+ DB_Nm +\".\"+ DB_Schema +\".\"+ Bod_Nm +\"_Flat \\n(\\n  BODNm\\t string\"\n",
    "    for index,row in merge_df.iterrows():\n",
    "        ddl = ddl + \"\\n  ,\" + row.new_sel_col + \"\\t string\"\n",
    "    ddl = ddl + \"\\n  ,DW_CreateTs\\t timestamp\\n)\\nDATA_RETENTION_TIME_IN_DAYS = \"+ str(Rtn_tm) +\";\"\n",
    "    with open(Output_Dir+Bod_Nm+\"_Flat_DDL.sql\", \"w\") as text_file:\n",
    "        print(\"{}\".format(ddl), file=text_file)\n",
    "    text_file.close()\n",
    "def createDML(merge_df):\n",
    "    \"\"\"Prepares DML statements and writes into a File\"\"\"\n",
    "    dml = \"INSERT INTO \"+ DB_Nm +\".\"+ DB_Schema +\".\"+ Bod_Nm +\"_Flat \\n\"+ \"SELECT\\tBODNm\"\n",
    "    for index,row in merge_df.iterrows():\n",
    "        dml = dml + \"\\n\\t,\" + row.new_sel_col\n",
    "    dml = dml + \"\\n\\t,TO_TIMESTAMP_NTZ(CURRENT_TIMESTAMP) AS DW_CreateTs\\nFROM\\n\\t(\"\n",
    "    # Group the dataframe by full XML path for preparing DML\n",
    "    group_df = merge_df.groupby('sort_path')\n",
    "    i=1\n",
    "    m=1\n",
    "    z=1\n",
    "    for group_name, df in group_df:\n",
    "        j=1\n",
    "        for index, row in df.iterrows():\n",
    "            cl = \"column\" + str(row.sel_col_pos - 2)\n",
    "            if i == 1 and j == 1 and row.column3 == 'DocumentData':\n",
    "                dml = dml + \"\\n\\t SELECT\\t\"+ Var_Col +\":\\\"@\\\"::string AS BODNm\"\n",
    "                dml = dml + \"\\n\\t \\t,XMLGET(\"+ row[cl] +\".value,'Abs:\"+ row['element'] + \"'):\\\"$\\\"::string AS \" + row.new_sel_col\n",
    "                m = 0\n",
    "            elif i == 1 and j == 1:\n",
    "                dml = dml + \"\\n\\t SELECT\\n\\t \\tXMLGET(\"+ row[cl] +\".value,'Abs:\"+ row['element'] + \"'):\\\"$\\\"::string AS \" + row.new_sel_col\n",
    "            elif j == 1 and row.column3 == 'DocumentData' and m == 1:\n",
    "                dml = dml + \"\\nLEFT JOIN\\n\\t(\" + \"\\n\\t SELECT\\t\" + Var_Col +\":\\\"@\\\"::string AS BODNm\"\n",
    "                dml = dml + \"\\n\\t \\t,XMLGET(\"+ row[cl] +\".value,'Abs:\"+ row['element'] + \"'):\\\"$\\\"::string AS \" + row.new_sel_col\n",
    "                m = 0\n",
    "            elif j == 1:\n",
    "                dml = dml + \"\\nLEFT JOIN\\n\\t(\" + \"\\n\\t SELECT\"\n",
    "                dml = dml + \"\\n\\t \\tXMLGET(\"+ row[cl] +\".value,'Abs:\"+ row['element'] + \"'):\\\"$\\\"::string AS \" + row.new_sel_col\n",
    "            else:\n",
    "                dml = dml + \"\\n\\t \\t,XMLGET(\"+ row[cl] +\".value,'Abs:\"+ row['element'] + \"'):\\\"$\\\"::string AS \" + row.new_sel_col\n",
    "            j=j+1\n",
    "        dml = dml + \"\\n\\t \\t,\" + row['column2'] +\".SEQ::integer as SEQ\\n\\t \\t,\" + row['column2'] + \".index::integer as idx\"\n",
    "        for x in range(1,row.sel_col_pos - 1):\n",
    "            if x == 1:\n",
    "                dml = dml + \"\\n\\t FROM\\t\"+ DB_Nm + \".\" + DB_Schema + \".\" + Var_Tbl +\" tbl\"\n",
    "            elif x == 2:\n",
    "                dml = dml + \"\\n\\t \\t,LATERAL FLATTEN(tbl.\" + Var_Col + \":\\\"$\\\") \"+ row['column2']\n",
    "            else:\n",
    "                cl = \"column\" + str(x)\n",
    "                cl_prev = \"column\" + str(x-1)\n",
    "                dml = dml + \"\\n\\t \\t,LATERAL FLATTEN(\"+ row[cl_prev] + \".value:\\\"$\\\") \"+ row[cl]\n",
    "        k=1\n",
    "        for x in range(1,row.sel_col_pos - 2):\n",
    "            cl1 = \"column\" + str(x + 1)\n",
    "            cl2 = \"column\" + str(x + 2)\n",
    "            if k == 1:\n",
    "                dml = dml + \"\\n\\t WHERE\\t\"+ row[cl1] +\".value like '<\"+ row[cl2] +\">%'\"\n",
    "            elif k == 2:\n",
    "                if row.column3 == 'DocumentData':\n",
    "                    dml = dml + \"\\n\\t AND\\t\"+ row[cl1] +\".value like '<\"+ row[cl2] +\">%'\"\n",
    "                else:\n",
    "                    dml = dml + \"\\n\\t AND\\t\"+ row[cl1] +\".value like '<\"+ Parent_Tag + row[cl2] +\">%'\"\n",
    "            else:\n",
    "                dml = dml + \"\\n\\t AND\\t\"+ row[cl1] +\".value like '<\"+ Child_Tag + row[cl2] +\">%'\"    \n",
    "            k=k+1\n",
    "        cl3 = \"column\" + str(row.sel_col_pos - 1)\n",
    "        if i == 1:\n",
    "            dml = dml + \"\\n\\t) \"+ row[cl3]\n",
    "            join_dict = {row.column3 + str(row.sel_col_pos): row[cl3]\n",
    "                         ,row.column3 + str(row.sel_col_pos-1): row[cl3]\n",
    "                        }\n",
    "            prev_col_pos = row.sel_col_pos\n",
    "            prev_col3 = row.column3\n",
    "            first_col_pos = row.sel_col_pos\n",
    "            first_col3 = row.column3\n",
    "        else:\n",
    "            if row.sel_col_pos ==  prev_col_pos and row.column3 == prev_col3:\n",
    "                dml = dml + \"\\n\\t) \"+ row[cl3] + \" on \" + row[cl3] + \".SEQ = \" + join_dict[row.column3 + str(row.sel_col_pos-1)] + \".SEQ AND \" + row[cl3] + \".idx = \" + join_dict[row.column3 + str(row.sel_col_pos-1)] + \".idx\"\n",
    "            elif row.sel_col_pos ==  prev_col_pos and row.column3 != prev_col3 and z == 1:\n",
    "                dml = dml + \"\\n\\t) \"+ row[cl3] + \" on \" + row[cl3] + \".SEQ = \" + join_dict[first_col3 + str(first_col_pos)] + \".SEQ \"\n",
    "                join_dict[row.column3 + str(row.sel_col_pos)] = row[cl3]\n",
    "                join_dict[row.column3 + str(row.sel_col_pos-1)] = row[cl3]\n",
    "                z=0\n",
    "            elif row.sel_col_pos !=  prev_col_pos and row.column3 != prev_col3 and z == 1:\n",
    "                dml = dml + \"\\n\\t) \"+ row[cl3] + \" on \" + row[cl3] + \".SEQ = \" + join_dict[first_col3 + str(first_col_pos)] + \".SEQ \"\n",
    "                join_dict[row.column3 + str(row.sel_col_pos)] = row[cl3]\n",
    "                join_dict[row.column3 + str(row.sel_col_pos-1)] = row[cl3]\n",
    "                z=0\n",
    "            elif row.sel_col_pos >  prev_col_pos and row.column3 == prev_col3:\n",
    "                dml = dml + \"\\n\\t) \"+ row[cl3] + \" on \" + row[cl3] + \".SEQ = \" + join_dict[row.column3 + str(row.sel_col_pos-1)] + \".SEQ AND \" + row[cl3] + \".idx = \" + join_dict[row.column3 + str(row.sel_col_pos-1)] + \".idx\" + \"*** Check Join ***\"\n",
    "                join_dict[row.column3 + str(row.sel_col_pos)] = row[cl3]\n",
    "            elif row.sel_col_pos <  prev_col_pos and row.column3 == prev_col3:\n",
    "                dml = dml + \"\\n\\t) \"+ row[cl3] + \" on \" + row[cl3] + \".SEQ = \" + join_dict[row.column3 + str(row.sel_col_pos-1)] + \".SEQ AND \" + row[cl3] + \".idx = \" + join_dict[row.column3 + str(row.sel_col_pos-1)] + \".idx\" + \"*** Check Join ***\"\n",
    "            prev_col_pos = row.sel_col_pos\n",
    "            prev_col3 = row.column3\n",
    "        i=i+1\n",
    "    with open(Output_Dir+Bod_Nm+\"_Flat_DML.sql\", \"w\") as text_file:\n",
    "        print(\"{}\".format(dml), file=text_file)\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Global Variable Declaration ####\n",
    "Bod_Nm = 'GetRetailStore'        \n",
    "#Inupt_File = 'C:\\\\Users\\\\rkori00\\\\Documents\\\\Project\\\\Data Ingestion Snowflake\\\\GetRetailStore_XSD_Sample.xml'\n",
    "#Output_Dir = 'C:\\\\Users\\\\rkori00\\\\Documents\\\\Project\\\\Data Ingestion Snowflake\\\\Output\\\\'\n",
    "Inupt_File = 'C:\\\\SYUE\\\\XML\\\\GetRetailStore_XSD_Sample.xml'\n",
    "Output_Dir = 'C:\\\\SYUE\\\\XML\\\\'\n",
    "\n",
    "DB_Nm = 'EDM_REFINED_DEV_Yue'\n",
    "DB_Schema = 'SCRATCH'\n",
    "Rtn_tm = 7\n",
    "Var_Tbl = 'ESED_RETAILSTORE'\n",
    "Var_Col = 'SRC_XML'\n",
    "Parent_Tag = 'Abs:'\n",
    "Child_Tag = 'Abs:'\n",
    "my_list = []\n",
    "split_tags = []\n",
    "path_list = []\n",
    "last1 = []\n",
    "all_tags = []\n",
    "cols = []\n",
    "split_cols = []\n",
    "new_col_lst = []\n",
    "sort_path = []\n",
    "####### End variable Declaration ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 3, column 2 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3325\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-4-8a483b5272b4>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    tree = ET.parse(Inupt_File)\n",
      "  File \u001b[0;32m\"C:\\ProgramData\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[0m, line \u001b[0;32m1197\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    tree.parse(source, parser)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\ProgramData\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[1;36m, line \u001b[1;32m598\u001b[1;36m, in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    self._root = parser._parse_whole(source)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mParseError\u001b[0m\u001b[1;31m:\u001b[0m not well-formed (invalid token): line 3, column 2\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse(Inupt_File)\n",
    "root = tree.getroot()\n",
    "parseXML(root,\"\")\n",
    "#print (my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(OrderedDict.fromkeys(my_list))\n",
    "#print (my_list)\n",
    "len_max = colList()\n",
    "splitTags(len_max)\n",
    "#creating Dataframe with all tags as columns\n",
    "all_tags_df = pd.DataFrame(columns=cols, data=all_tags)\n",
    "#creating Dataframe with last element and its position occurence in the XML tag\n",
    "col_df = pd.DataFrame(columns=['sel_col','sel_col_pos'], data=last1)\n",
    "col_df['sel_col'] = col_df['sel_col'].str[0]\n",
    "# Merging both dataframes to form consolidated data frame\n",
    "merge_df = all_tags_df.join(col_df)\n",
    "merge_df = renameDupCols(merge_df)\n",
    "# Append full the XML path as a column to the existing dataframe\n",
    "path_df = pd.DataFrame(columns=['path','element'], data=path_list)\n",
    "sort_df = pd.DataFrame(columns=['sort_path'], data=sort_path)\n",
    "merge_df = merge_df.join(path_df)\n",
    "merge_df = merge_df.join(sort_df)\n",
    "createDDL(merge_df)\n",
    "createDML(merge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
